{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datasets\n",
    "from datasets import inspect_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.v2 import Compose, Normalize, ToImage, ToDtype\n",
    "from fmnist_models import MLP, CNN, train\n",
    "from transformers import AutoImageProcessor, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Figure out how to normalize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"fashion_mnist\")\n",
    "transform = Compose([ToImage(), ToDtype(torch.float32, scale=True), Normalize(mean=[0.2860], std=[0.3530])])\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 106506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c906610f9fea40578689fdc6167ed22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3019, 'grad_norm': 0.18692916631698608, 'learning_rate': 4.273504273504274e-06, 'epoch': 0.09}\n",
      "{'loss': 2.3015, 'grad_norm': 0.17187148332595825, 'learning_rate': 8.547008547008548e-06, 'epoch': 0.17}\n",
      "{'loss': 2.2992, 'grad_norm': 0.2027575969696045, 'learning_rate': 1.282051282051282e-05, 'epoch': 0.26}\n",
      "{'loss': 2.2957, 'grad_norm': 0.19074523448944092, 'learning_rate': 1.7094017094017095e-05, 'epoch': 0.34}\n",
      "{'loss': 2.2902, 'grad_norm': 0.20945096015930176, 'learning_rate': 2.1367521367521368e-05, 'epoch': 0.43}\n",
      "{'loss': 2.2833, 'grad_norm': 0.23835505545139313, 'learning_rate': 2.564102564102564e-05, 'epoch': 0.51}\n",
      "{'loss': 2.2731, 'grad_norm': 0.28182336688041687, 'learning_rate': 2.9914529914529915e-05, 'epoch': 0.6}\n",
      "{'loss': 2.2547, 'grad_norm': 0.3428078591823578, 'learning_rate': 3.418803418803419e-05, 'epoch': 0.68}\n",
      "{'loss': 2.2285, 'grad_norm': 0.4427930414676666, 'learning_rate': 3.846153846153846e-05, 'epoch': 0.77}\n",
      "{'loss': 2.1879, 'grad_norm': 0.5461432933807373, 'learning_rate': 4.2735042735042735e-05, 'epoch': 0.85}\n",
      "{'loss': 2.1393, 'grad_norm': 0.5585764646530151, 'learning_rate': 4.700854700854701e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e191fbe53364e2c98a7c85756d134a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0552117824554443, 'eval_accuracy': 0.489, 'eval_runtime': 1.3952, 'eval_samples_per_second': 7167.251, 'eval_steps_per_second': 56.621, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.078, 'grad_norm': 0.7238411903381348, 'learning_rate': 4.985754985754986e-05, 'epoch': 1.02}\n",
      "{'loss': 2.018, 'grad_norm': 0.6510031223297119, 'learning_rate': 4.938271604938271e-05, 'epoch': 1.11}\n",
      "{'loss': 1.9579, 'grad_norm': 0.5378130674362183, 'learning_rate': 4.890788224121557e-05, 'epoch': 1.19}\n",
      "{'loss': 1.9196, 'grad_norm': 0.4793243110179901, 'learning_rate': 4.8433048433048433e-05, 'epoch': 1.28}\n",
      "{'loss': 1.8939, 'grad_norm': 0.5457066297531128, 'learning_rate': 4.7958214624881294e-05, 'epoch': 1.36}\n",
      "{'loss': 1.8776, 'grad_norm': 0.6576974987983704, 'learning_rate': 4.7483380816714154e-05, 'epoch': 1.45}\n",
      "{'loss': 1.857, 'grad_norm': 0.6575126051902771, 'learning_rate': 4.700854700854701e-05, 'epoch': 1.54}\n",
      "{'loss': 1.8491, 'grad_norm': 0.548642098903656, 'learning_rate': 4.653371320037987e-05, 'epoch': 1.62}\n",
      "{'loss': 1.831, 'grad_norm': 0.5755109190940857, 'learning_rate': 4.605887939221273e-05, 'epoch': 1.71}\n",
      "{'loss': 1.8272, 'grad_norm': 0.474594384431839, 'learning_rate': 4.558404558404559e-05, 'epoch': 1.79}\n",
      "{'loss': 1.817, 'grad_norm': 0.5661405920982361, 'learning_rate': 4.510921177587845e-05, 'epoch': 1.88}\n",
      "{'loss': 1.8045, 'grad_norm': 0.5386542677879333, 'learning_rate': 4.463437796771131e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16be10b0f2f94cbb873fdea0e6fdb9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7909363508224487, 'eval_accuracy': 0.71, 'eval_runtime': 1.4251, 'eval_samples_per_second': 7017.165, 'eval_steps_per_second': 55.436, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.791, 'grad_norm': 0.6842477321624756, 'learning_rate': 4.415954415954416e-05, 'epoch': 2.05}\n",
      "{'loss': 1.7951, 'grad_norm': 0.462130606174469, 'learning_rate': 4.368471035137702e-05, 'epoch': 2.13}\n",
      "{'loss': 1.7825, 'grad_norm': 0.4745323657989502, 'learning_rate': 4.3209876543209875e-05, 'epoch': 2.22}\n",
      "{'loss': 1.7759, 'grad_norm': 0.6558297872543335, 'learning_rate': 4.2735042735042735e-05, 'epoch': 2.3}\n",
      "{'loss': 1.7738, 'grad_norm': 0.5929506421089172, 'learning_rate': 4.2260208926875595e-05, 'epoch': 2.39}\n",
      "{'loss': 1.764, 'grad_norm': 0.5352249145507812, 'learning_rate': 4.1785375118708455e-05, 'epoch': 2.47}\n",
      "{'loss': 1.7702, 'grad_norm': 0.5660427212715149, 'learning_rate': 4.131054131054131e-05, 'epoch': 2.56}\n",
      "{'loss': 1.7617, 'grad_norm': 0.49604523181915283, 'learning_rate': 4.083570750237417e-05, 'epoch': 2.64}\n",
      "{'loss': 1.7565, 'grad_norm': 0.5551466941833496, 'learning_rate': 4.036087369420703e-05, 'epoch': 2.73}\n",
      "{'loss': 1.7567, 'grad_norm': 0.5086965560913086, 'learning_rate': 3.988603988603989e-05, 'epoch': 2.81}\n",
      "{'loss': 1.7452, 'grad_norm': 0.6804952025413513, 'learning_rate': 3.941120607787275e-05, 'epoch': 2.9}\n",
      "{'loss': 1.7454, 'grad_norm': 0.6694866418838501, 'learning_rate': 3.893637226970561e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abae43851a70431dae69f064c227c275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7427347898483276, 'eval_accuracy': 0.7415, 'eval_runtime': 1.4065, 'eval_samples_per_second': 7110.089, 'eval_steps_per_second': 56.17, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7432, 'grad_norm': 0.4468410313129425, 'learning_rate': 3.846153846153846e-05, 'epoch': 3.07}\n",
      "{'loss': 1.7463, 'grad_norm': 0.6533463597297668, 'learning_rate': 3.798670465337132e-05, 'epoch': 3.16}\n",
      "{'loss': 1.7481, 'grad_norm': 0.4890691041946411, 'learning_rate': 3.7511870845204176e-05, 'epoch': 3.24}\n",
      "{'loss': 1.7433, 'grad_norm': 0.4925867021083832, 'learning_rate': 3.7037037037037037e-05, 'epoch': 3.33}\n",
      "{'loss': 1.7355, 'grad_norm': 0.6657668948173523, 'learning_rate': 3.65622032288699e-05, 'epoch': 3.41}\n",
      "{'loss': 1.739, 'grad_norm': 0.5627389550209045, 'learning_rate': 3.608736942070276e-05, 'epoch': 3.5}\n",
      "{'loss': 1.7444, 'grad_norm': 0.4726216495037079, 'learning_rate': 3.561253561253561e-05, 'epoch': 3.58}\n",
      "{'loss': 1.7362, 'grad_norm': 0.4759889543056488, 'learning_rate': 3.513770180436847e-05, 'epoch': 3.67}\n",
      "{'loss': 1.728, 'grad_norm': 0.5613358616828918, 'learning_rate': 3.466286799620133e-05, 'epoch': 3.75}\n",
      "{'loss': 1.7304, 'grad_norm': 0.4005991816520691, 'learning_rate': 3.418803418803419e-05, 'epoch': 3.84}\n",
      "{'loss': 1.7254, 'grad_norm': 0.6580754518508911, 'learning_rate': 3.371320037986705e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9af80767094c54b44ffb921b679601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7229762077331543, 'eval_accuracy': 0.7537, 'eval_runtime': 1.3839, 'eval_samples_per_second': 7225.899, 'eval_steps_per_second': 57.085, 'epoch': 4.0}\n",
      "{'loss': 1.7186, 'grad_norm': 0.47856467962265015, 'learning_rate': 3.323836657169991e-05, 'epoch': 4.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.727, 'grad_norm': 0.5356930494308472, 'learning_rate': 3.2763532763532764e-05, 'epoch': 4.09}\n",
      "{'loss': 1.7254, 'grad_norm': 0.5568737387657166, 'learning_rate': 3.2288698955365625e-05, 'epoch': 4.18}\n",
      "{'loss': 1.7138, 'grad_norm': 0.5096388459205627, 'learning_rate': 3.181386514719848e-05, 'epoch': 4.26}\n",
      "{'loss': 1.7268, 'grad_norm': 0.5396839380264282, 'learning_rate': 3.133903133903134e-05, 'epoch': 4.35}\n",
      "{'loss': 1.7189, 'grad_norm': 0.48535335063934326, 'learning_rate': 3.08641975308642e-05, 'epoch': 4.43}\n",
      "{'loss': 1.727, 'grad_norm': 0.5055564641952515, 'learning_rate': 3.0389363722697055e-05, 'epoch': 4.52}\n",
      "{'loss': 1.7257, 'grad_norm': 0.6019004583358765, 'learning_rate': 2.9914529914529915e-05, 'epoch': 4.61}\n",
      "{'loss': 1.7097, 'grad_norm': 0.4594396948814392, 'learning_rate': 2.9439696106362775e-05, 'epoch': 4.69}\n",
      "{'loss': 1.7151, 'grad_norm': 0.5734356045722961, 'learning_rate': 2.8964862298195632e-05, 'epoch': 4.78}\n",
      "{'loss': 1.7175, 'grad_norm': 0.5260999202728271, 'learning_rate': 2.8490028490028492e-05, 'epoch': 4.86}\n",
      "{'loss': 1.7178, 'grad_norm': 0.4892691373825073, 'learning_rate': 2.8015194681861352e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3073a9db24594767a67be0d5be9d64a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7110164165496826, 'eval_accuracy': 0.7644, 'eval_runtime': 1.4225, 'eval_samples_per_second': 7029.773, 'eval_steps_per_second': 55.535, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7147, 'grad_norm': 0.4632071852684021, 'learning_rate': 2.754036087369421e-05, 'epoch': 5.03}\n",
      "{'loss': 1.7124, 'grad_norm': 0.5628951191902161, 'learning_rate': 2.706552706552707e-05, 'epoch': 5.12}\n",
      "{'loss': 1.7155, 'grad_norm': 0.548023521900177, 'learning_rate': 2.6590693257359926e-05, 'epoch': 5.2}\n",
      "{'loss': 1.7111, 'grad_norm': 0.6006879210472107, 'learning_rate': 2.611585944919278e-05, 'epoch': 5.29}\n",
      "{'loss': 1.707, 'grad_norm': 0.6153220534324646, 'learning_rate': 2.564102564102564e-05, 'epoch': 5.37}\n",
      "{'loss': 1.7125, 'grad_norm': 0.4452708065509796, 'learning_rate': 2.51661918328585e-05, 'epoch': 5.46}\n",
      "{'loss': 1.7174, 'grad_norm': 0.5169723629951477, 'learning_rate': 2.4691358024691357e-05, 'epoch': 5.54}\n",
      "{'loss': 1.7113, 'grad_norm': 0.4908588230609894, 'learning_rate': 2.4216524216524217e-05, 'epoch': 5.63}\n",
      "{'loss': 1.7054, 'grad_norm': 0.537900984287262, 'learning_rate': 2.3741690408357077e-05, 'epoch': 5.71}\n",
      "{'loss': 1.7126, 'grad_norm': 0.5564411282539368, 'learning_rate': 2.3266856600189934e-05, 'epoch': 5.8}\n",
      "{'loss': 1.7055, 'grad_norm': 0.4824528992176056, 'learning_rate': 2.2792022792022794e-05, 'epoch': 5.88}\n",
      "{'loss': 1.7081, 'grad_norm': 0.6197798252105713, 'learning_rate': 2.2317188983855654e-05, 'epoch': 5.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a2ae840abe4daeb73bc87a3add0cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7029484510421753, 'eval_accuracy': 0.774, 'eval_runtime': 1.4201, 'eval_samples_per_second': 7041.648, 'eval_steps_per_second': 55.629, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7074, 'grad_norm': 0.4416179955005646, 'learning_rate': 2.184235517568851e-05, 'epoch': 6.06}\n",
      "{'loss': 1.7096, 'grad_norm': 0.522028923034668, 'learning_rate': 2.1367521367521368e-05, 'epoch': 6.14}\n",
      "{'loss': 1.7057, 'grad_norm': 0.44702380895614624, 'learning_rate': 2.0892687559354228e-05, 'epoch': 6.23}\n",
      "{'loss': 1.6962, 'grad_norm': 0.4843115508556366, 'learning_rate': 2.0417853751187084e-05, 'epoch': 6.31}\n",
      "{'loss': 1.6995, 'grad_norm': 0.46359020471572876, 'learning_rate': 1.9943019943019945e-05, 'epoch': 6.4}\n",
      "{'loss': 1.7048, 'grad_norm': 0.5041469931602478, 'learning_rate': 1.9468186134852805e-05, 'epoch': 6.48}\n",
      "{'loss': 1.7119, 'grad_norm': 0.6114515662193298, 'learning_rate': 1.899335232668566e-05, 'epoch': 6.57}\n",
      "{'loss': 1.6986, 'grad_norm': 0.6555495858192444, 'learning_rate': 1.8518518518518518e-05, 'epoch': 6.65}\n",
      "{'loss': 1.7029, 'grad_norm': 0.7611258029937744, 'learning_rate': 1.804368471035138e-05, 'epoch': 6.74}\n",
      "{'loss': 1.6956, 'grad_norm': 0.502175509929657, 'learning_rate': 1.7568850902184235e-05, 'epoch': 6.82}\n",
      "{'loss': 1.6966, 'grad_norm': 0.631106972694397, 'learning_rate': 1.7094017094017095e-05, 'epoch': 6.91}\n",
      "{'loss': 1.7107, 'grad_norm': 0.5388549566268921, 'learning_rate': 1.6619183285849956e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963d0bd042e743d9a0f59e0b92a11f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6975152492523193, 'eval_accuracy': 0.7777, 'eval_runtime': 1.4424, 'eval_samples_per_second': 6933.117, 'eval_steps_per_second': 54.772, 'epoch': 6.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7, 'grad_norm': 0.5099855065345764, 'learning_rate': 1.6144349477682812e-05, 'epoch': 7.08}\n",
      "{'loss': 1.7009, 'grad_norm': 0.45134732127189636, 'learning_rate': 1.566951566951567e-05, 'epoch': 7.16}\n",
      "{'loss': 1.6907, 'grad_norm': 0.45179829001426697, 'learning_rate': 1.5194681861348528e-05, 'epoch': 7.25}\n",
      "{'loss': 1.6967, 'grad_norm': 0.47423309087753296, 'learning_rate': 1.4719848053181388e-05, 'epoch': 7.33}\n",
      "{'loss': 1.7089, 'grad_norm': 0.4582500159740448, 'learning_rate': 1.4245014245014246e-05, 'epoch': 7.42}\n",
      "{'loss': 1.7035, 'grad_norm': 0.503612756729126, 'learning_rate': 1.3770180436847105e-05, 'epoch': 7.51}\n",
      "{'loss': 1.6977, 'grad_norm': 0.4390881061553955, 'learning_rate': 1.3295346628679963e-05, 'epoch': 7.59}\n",
      "{'loss': 1.6933, 'grad_norm': 0.504296064376831, 'learning_rate': 1.282051282051282e-05, 'epoch': 7.68}\n",
      "{'loss': 1.6935, 'grad_norm': 0.458760142326355, 'learning_rate': 1.2345679012345678e-05, 'epoch': 7.76}\n",
      "{'loss': 1.7014, 'grad_norm': 0.4728432893753052, 'learning_rate': 1.1870845204178538e-05, 'epoch': 7.85}\n",
      "{'loss': 1.6978, 'grad_norm': 0.41784748435020447, 'learning_rate': 1.1396011396011397e-05, 'epoch': 7.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8f839b18ac4fc0b116c460d935a1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6938382387161255, 'eval_accuracy': 0.7809, 'eval_runtime': 1.3608, 'eval_samples_per_second': 7348.591, 'eval_steps_per_second': 58.054, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.703, 'grad_norm': 0.431794673204422, 'learning_rate': 1.0921177587844255e-05, 'epoch': 8.02}\n",
      "{'loss': 1.7031, 'grad_norm': 0.6875536441802979, 'learning_rate': 1.0446343779677114e-05, 'epoch': 8.1}\n",
      "{'loss': 1.7016, 'grad_norm': 0.5967649221420288, 'learning_rate': 9.971509971509972e-06, 'epoch': 8.19}\n",
      "{'loss': 1.7019, 'grad_norm': 0.583902895450592, 'learning_rate': 9.49667616334283e-06, 'epoch': 8.27}\n",
      "{'loss': 1.6916, 'grad_norm': 0.45443660020828247, 'learning_rate': 9.02184235517569e-06, 'epoch': 8.36}\n",
      "{'loss': 1.6927, 'grad_norm': 0.5751610398292542, 'learning_rate': 8.547008547008548e-06, 'epoch': 8.44}\n",
      "{'loss': 1.6972, 'grad_norm': 0.5105316042900085, 'learning_rate': 8.072174738841406e-06, 'epoch': 8.53}\n",
      "{'loss': 1.6929, 'grad_norm': 0.5470250248908997, 'learning_rate': 7.597340930674264e-06, 'epoch': 8.61}\n",
      "{'loss': 1.7001, 'grad_norm': 0.5834125876426697, 'learning_rate': 7.122507122507123e-06, 'epoch': 8.7}\n",
      "{'loss': 1.6873, 'grad_norm': 0.7156885266304016, 'learning_rate': 6.6476733143399815e-06, 'epoch': 8.78}\n",
      "{'loss': 1.6947, 'grad_norm': 0.5528779029846191, 'learning_rate': 6.172839506172839e-06, 'epoch': 8.87}\n",
      "{'loss': 1.6945, 'grad_norm': 0.47917401790618896, 'learning_rate': 5.6980056980056985e-06, 'epoch': 8.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af53e1482cb46f7b06f2cf7bf4188d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6918400526046753, 'eval_accuracy': 0.7838, 'eval_runtime': 1.4409, 'eval_samples_per_second': 6940.01, 'eval_steps_per_second': 54.826, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/2j0g58f94vnf8m_5r3z2k4dr0000gn/T/ipykernel_2116/3338567670.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  examples[\"pixel_values\"] = [torch.tensor(transform(image)) for image in examples[\"image\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6896, 'grad_norm': 0.5594640970230103, 'learning_rate': 5.223171889838557e-06, 'epoch': 9.04}\n",
      "{'loss': 1.6955, 'grad_norm': 0.5319828987121582, 'learning_rate': 4.748338081671415e-06, 'epoch': 9.13}\n",
      "{'loss': 1.6956, 'grad_norm': 0.5736562609672546, 'learning_rate': 4.273504273504274e-06, 'epoch': 9.21}\n",
      "{'loss': 1.6884, 'grad_norm': 0.4775325059890747, 'learning_rate': 3.798670465337132e-06, 'epoch': 9.3}\n",
      "{'loss': 1.6991, 'grad_norm': 0.47366777062416077, 'learning_rate': 3.3238366571699908e-06, 'epoch': 9.38}\n",
      "{'loss': 1.6861, 'grad_norm': 0.6080653071403503, 'learning_rate': 2.8490028490028492e-06, 'epoch': 9.47}\n",
      "{'loss': 1.6938, 'grad_norm': 0.45435380935668945, 'learning_rate': 2.3741690408357077e-06, 'epoch': 9.55}\n",
      "{'loss': 1.6976, 'grad_norm': 0.701070249080658, 'learning_rate': 1.899335232668566e-06, 'epoch': 9.64}\n",
      "{'loss': 1.6991, 'grad_norm': 0.5925618410110474, 'learning_rate': 1.4245014245014246e-06, 'epoch': 9.72}\n",
      "{'loss': 1.6947, 'grad_norm': 0.5760884881019592, 'learning_rate': 9.49667616334283e-07, 'epoch': 9.81}\n",
      "{'loss': 1.6952, 'grad_norm': 0.4987981617450714, 'learning_rate': 4.748338081671415e-07, 'epoch': 9.89}\n",
      "{'loss': 1.6982, 'grad_norm': 0.5245612263679504, 'learning_rate': 0.0, 'epoch': 9.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3085bfe34e4349b09b8ff19180f4f36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6911110877990723, 'eval_accuracy': 0.7833, 'eval_runtime': 1.3585, 'eval_samples_per_second': 7360.946, 'eval_steps_per_second': 58.151, 'epoch': 9.98}\n",
      "{'train_runtime': 120.0377, 'train_samples_per_second': 4998.429, 'train_steps_per_second': 9.747, 'train_loss': 1.7856239286243407, 'epoch': 9.98}\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"fashion_mnist\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    use_mps_device=True,\n",
    ")\n",
    "trainer = train(MLP, dataset, train_args, d_in=28*28, d_hidden=28*28, d_out=10)\n",
    "# trainer = train(CNN, dataset, train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.3022,\n",
       "  'grad_norm': 0.020899033173918724,\n",
       "  'learning_rate': 4.273504273504274e-06,\n",
       "  'epoch': 0.09,\n",
       "  'step': 10},\n",
       " {'loss': 2.3019,\n",
       "  'grad_norm': 0.020860455930233,\n",
       "  'learning_rate': 8.547008547008548e-06,\n",
       "  'epoch': 0.17,\n",
       "  'step': 20},\n",
       " {'loss': 2.301,\n",
       "  'grad_norm': 0.02217506244778633,\n",
       "  'learning_rate': 1.282051282051282e-05,\n",
       "  'epoch': 0.26,\n",
       "  'step': 30},\n",
       " {'loss': 2.2995,\n",
       "  'grad_norm': 0.024014804512262344,\n",
       "  'learning_rate': 1.7094017094017095e-05,\n",
       "  'epoch': 0.34,\n",
       "  'step': 40},\n",
       " {'loss': 2.2968,\n",
       "  'grad_norm': 0.030760394409298897,\n",
       "  'learning_rate': 2.1367521367521368e-05,\n",
       "  'epoch': 0.43,\n",
       "  'step': 50},\n",
       " {'loss': 2.2921,\n",
       "  'grad_norm': 0.04679757356643677,\n",
       "  'learning_rate': 2.564102564102564e-05,\n",
       "  'epoch': 0.51,\n",
       "  'step': 60},\n",
       " {'loss': 2.2826,\n",
       "  'grad_norm': 0.07243793457746506,\n",
       "  'learning_rate': 2.9914529914529915e-05,\n",
       "  'epoch': 0.6,\n",
       "  'step': 70},\n",
       " {'loss': 2.2612,\n",
       "  'grad_norm': 0.13746219873428345,\n",
       "  'learning_rate': 3.418803418803419e-05,\n",
       "  'epoch': 0.68,\n",
       "  'step': 80},\n",
       " {'loss': 2.2132,\n",
       "  'grad_norm': 0.20504102110862732,\n",
       "  'learning_rate': 3.846153846153846e-05,\n",
       "  'epoch': 0.77,\n",
       "  'step': 90},\n",
       " {'loss': 2.1377,\n",
       "  'grad_norm': 0.32367071509361267,\n",
       "  'learning_rate': 4.2735042735042735e-05,\n",
       "  'epoch': 0.85,\n",
       "  'step': 100},\n",
       " {'loss': 2.0357,\n",
       "  'grad_norm': 0.2644730806350708,\n",
       "  'learning_rate': 4.700854700854701e-05,\n",
       "  'epoch': 0.94,\n",
       "  'step': 110},\n",
       " {'eval_loss': 1.938960313796997,\n",
       "  'eval_accuracy': 0.5681,\n",
       "  'eval_runtime': 1.165,\n",
       "  'eval_samples_per_second': 8583.486,\n",
       "  'eval_steps_per_second': 67.81,\n",
       "  'epoch': 1.0,\n",
       "  'step': 117},\n",
       " {'loss': 1.9626,\n",
       "  'grad_norm': 0.4224201440811157,\n",
       "  'learning_rate': 4.985754985754986e-05,\n",
       "  'epoch': 1.02,\n",
       "  'step': 120},\n",
       " {'loss': 1.9107,\n",
       "  'grad_norm': 0.49584585428237915,\n",
       "  'learning_rate': 4.938271604938271e-05,\n",
       "  'epoch': 1.11,\n",
       "  'step': 130},\n",
       " {'loss': 1.8703,\n",
       "  'grad_norm': 0.2986878752708435,\n",
       "  'learning_rate': 4.890788224121557e-05,\n",
       "  'epoch': 1.19,\n",
       "  'step': 140},\n",
       " {'loss': 1.8484,\n",
       "  'grad_norm': 0.43735724687576294,\n",
       "  'learning_rate': 4.8433048433048433e-05,\n",
       "  'epoch': 1.28,\n",
       "  'step': 150},\n",
       " {'loss': 1.8184,\n",
       "  'grad_norm': 0.28505975008010864,\n",
       "  'learning_rate': 4.7958214624881294e-05,\n",
       "  'epoch': 1.36,\n",
       "  'step': 160},\n",
       " {'loss': 1.8052,\n",
       "  'grad_norm': 0.38131988048553467,\n",
       "  'learning_rate': 4.7483380816714154e-05,\n",
       "  'epoch': 1.45,\n",
       "  'step': 170},\n",
       " {'loss': 1.8011,\n",
       "  'grad_norm': 0.3772508203983307,\n",
       "  'learning_rate': 4.700854700854701e-05,\n",
       "  'epoch': 1.54,\n",
       "  'step': 180},\n",
       " {'loss': 1.7905,\n",
       "  'grad_norm': 0.32194581627845764,\n",
       "  'learning_rate': 4.653371320037987e-05,\n",
       "  'epoch': 1.62,\n",
       "  'step': 190},\n",
       " {'loss': 1.7752,\n",
       "  'grad_norm': 0.24808114767074585,\n",
       "  'learning_rate': 4.605887939221273e-05,\n",
       "  'epoch': 1.71,\n",
       "  'step': 200},\n",
       " {'loss': 1.7778,\n",
       "  'grad_norm': 0.19890601933002472,\n",
       "  'learning_rate': 4.558404558404559e-05,\n",
       "  'epoch': 1.79,\n",
       "  'step': 210},\n",
       " {'loss': 1.7589,\n",
       "  'grad_norm': 0.2170187383890152,\n",
       "  'learning_rate': 4.510921177587845e-05,\n",
       "  'epoch': 1.88,\n",
       "  'step': 220},\n",
       " {'loss': 1.7526,\n",
       "  'grad_norm': 0.3079814016819,\n",
       "  'learning_rate': 4.463437796771131e-05,\n",
       "  'epoch': 1.96,\n",
       "  'step': 230},\n",
       " {'eval_loss': 1.74656343460083,\n",
       "  'eval_accuracy': 0.7432,\n",
       "  'eval_runtime': 1.1786,\n",
       "  'eval_samples_per_second': 8484.455,\n",
       "  'eval_steps_per_second': 67.027,\n",
       "  'epoch': 2.0,\n",
       "  'step': 234},\n",
       " {'loss': 1.7405,\n",
       "  'grad_norm': 0.4755485951900482,\n",
       "  'learning_rate': 4.415954415954416e-05,\n",
       "  'epoch': 2.05,\n",
       "  'step': 240},\n",
       " {'loss': 1.7435,\n",
       "  'grad_norm': 0.5026156902313232,\n",
       "  'learning_rate': 4.368471035137702e-05,\n",
       "  'epoch': 2.13,\n",
       "  'step': 250},\n",
       " {'loss': 1.7317,\n",
       "  'grad_norm': 0.39456385374069214,\n",
       "  'learning_rate': 4.3209876543209875e-05,\n",
       "  'epoch': 2.22,\n",
       "  'step': 260},\n",
       " {'loss': 1.7189,\n",
       "  'grad_norm': 0.6211690902709961,\n",
       "  'learning_rate': 4.2735042735042735e-05,\n",
       "  'epoch': 2.3,\n",
       "  'step': 270},\n",
       " {'loss': 1.7228,\n",
       "  'grad_norm': 0.2783777415752411,\n",
       "  'learning_rate': 4.2260208926875595e-05,\n",
       "  'epoch': 2.39,\n",
       "  'step': 280},\n",
       " {'loss': 1.722,\n",
       "  'grad_norm': 0.5557811856269836,\n",
       "  'learning_rate': 4.1785375118708455e-05,\n",
       "  'epoch': 2.47,\n",
       "  'step': 290},\n",
       " {'loss': 1.7234,\n",
       "  'grad_norm': 0.33858048915863037,\n",
       "  'learning_rate': 4.131054131054131e-05,\n",
       "  'epoch': 2.56,\n",
       "  'step': 300},\n",
       " {'loss': 1.713,\n",
       "  'grad_norm': 0.2588602602481842,\n",
       "  'learning_rate': 4.083570750237417e-05,\n",
       "  'epoch': 2.64,\n",
       "  'step': 310},\n",
       " {'loss': 1.7061,\n",
       "  'grad_norm': 0.33779236674308777,\n",
       "  'learning_rate': 4.036087369420703e-05,\n",
       "  'epoch': 2.73,\n",
       "  'step': 320},\n",
       " {'loss': 1.7107,\n",
       "  'grad_norm': 0.2825223505496979,\n",
       "  'learning_rate': 3.988603988603989e-05,\n",
       "  'epoch': 2.81,\n",
       "  'step': 330},\n",
       " {'loss': 1.6997,\n",
       "  'grad_norm': 0.4446536898612976,\n",
       "  'learning_rate': 3.941120607787275e-05,\n",
       "  'epoch': 2.9,\n",
       "  'step': 340},\n",
       " {'loss': 1.696,\n",
       "  'grad_norm': 0.430843710899353,\n",
       "  'learning_rate': 3.893637226970561e-05,\n",
       "  'epoch': 2.99,\n",
       "  'step': 350},\n",
       " {'eval_loss': 1.7026538848876953,\n",
       "  'eval_accuracy': 0.7743,\n",
       "  'eval_runtime': 1.1497,\n",
       "  'eval_samples_per_second': 8697.685,\n",
       "  'eval_steps_per_second': 68.712,\n",
       "  'epoch': 2.99,\n",
       "  'step': 351},\n",
       " {'loss': 1.6936,\n",
       "  'grad_norm': 0.18034256994724274,\n",
       "  'learning_rate': 3.846153846153846e-05,\n",
       "  'epoch': 3.07,\n",
       "  'step': 360},\n",
       " {'loss': 1.6984,\n",
       "  'grad_norm': 0.22711758315563202,\n",
       "  'learning_rate': 3.798670465337132e-05,\n",
       "  'epoch': 3.16,\n",
       "  'step': 370},\n",
       " {'loss': 1.6983,\n",
       "  'grad_norm': 0.26926013827323914,\n",
       "  'learning_rate': 3.7511870845204176e-05,\n",
       "  'epoch': 3.24,\n",
       "  'step': 380},\n",
       " {'loss': 1.6983,\n",
       "  'grad_norm': 0.3488827645778656,\n",
       "  'learning_rate': 3.7037037037037037e-05,\n",
       "  'epoch': 3.33,\n",
       "  'step': 390},\n",
       " {'loss': 1.6926,\n",
       "  'grad_norm': 0.5345696806907654,\n",
       "  'learning_rate': 3.65622032288699e-05,\n",
       "  'epoch': 3.41,\n",
       "  'step': 400},\n",
       " {'loss': 1.6966,\n",
       "  'grad_norm': 0.2425864040851593,\n",
       "  'learning_rate': 3.608736942070276e-05,\n",
       "  'epoch': 3.5,\n",
       "  'step': 410},\n",
       " {'loss': 1.7034,\n",
       "  'grad_norm': 0.23445577919483185,\n",
       "  'learning_rate': 3.561253561253561e-05,\n",
       "  'epoch': 3.58,\n",
       "  'step': 420},\n",
       " {'loss': 1.6875,\n",
       "  'grad_norm': 0.3192095458507538,\n",
       "  'learning_rate': 3.513770180436847e-05,\n",
       "  'epoch': 3.67,\n",
       "  'step': 430},\n",
       " {'loss': 1.6858,\n",
       "  'grad_norm': 0.46072500944137573,\n",
       "  'learning_rate': 3.466286799620133e-05,\n",
       "  'epoch': 3.75,\n",
       "  'step': 440},\n",
       " {'loss': 1.6911,\n",
       "  'grad_norm': 0.2520236074924469,\n",
       "  'learning_rate': 3.418803418803419e-05,\n",
       "  'epoch': 3.84,\n",
       "  'step': 450},\n",
       " {'loss': 1.687,\n",
       "  'grad_norm': 0.22253966331481934,\n",
       "  'learning_rate': 3.371320037986705e-05,\n",
       "  'epoch': 3.92,\n",
       "  'step': 460},\n",
       " {'eval_loss': 1.6897683143615723,\n",
       "  'eval_accuracy': 0.7805,\n",
       "  'eval_runtime': 1.1348,\n",
       "  'eval_samples_per_second': 8812.102,\n",
       "  'eval_steps_per_second': 69.616,\n",
       "  'epoch': 4.0,\n",
       "  'step': 469},\n",
       " {'loss': 1.6791,\n",
       "  'grad_norm': 0.48152658343315125,\n",
       "  'learning_rate': 3.323836657169991e-05,\n",
       "  'epoch': 4.01,\n",
       "  'step': 470},\n",
       " {'loss': 1.686,\n",
       "  'grad_norm': 0.26819825172424316,\n",
       "  'learning_rate': 3.2763532763532764e-05,\n",
       "  'epoch': 4.09,\n",
       "  'step': 480},\n",
       " {'loss': 1.6863,\n",
       "  'grad_norm': 0.19079019129276276,\n",
       "  'learning_rate': 3.2288698955365625e-05,\n",
       "  'epoch': 4.18,\n",
       "  'step': 490},\n",
       " {'loss': 1.6772,\n",
       "  'grad_norm': 0.3008117377758026,\n",
       "  'learning_rate': 3.181386514719848e-05,\n",
       "  'epoch': 4.26,\n",
       "  'step': 500},\n",
       " {'loss': 1.6966,\n",
       "  'grad_norm': 0.29390138387680054,\n",
       "  'learning_rate': 3.133903133903134e-05,\n",
       "  'epoch': 4.35,\n",
       "  'step': 510},\n",
       " {'loss': 1.6818,\n",
       "  'grad_norm': 0.24262197315692902,\n",
       "  'learning_rate': 3.08641975308642e-05,\n",
       "  'epoch': 4.43,\n",
       "  'step': 520},\n",
       " {'loss': 1.6844,\n",
       "  'grad_norm': 0.24306797981262207,\n",
       "  'learning_rate': 3.0389363722697055e-05,\n",
       "  'epoch': 4.52,\n",
       "  'step': 530},\n",
       " {'loss': 1.6888,\n",
       "  'grad_norm': 0.23041830956935883,\n",
       "  'learning_rate': 2.9914529914529915e-05,\n",
       "  'epoch': 4.61,\n",
       "  'step': 540},\n",
       " {'loss': 1.6705,\n",
       "  'grad_norm': 0.29132315516471863,\n",
       "  'learning_rate': 2.9439696106362775e-05,\n",
       "  'epoch': 4.69,\n",
       "  'step': 550},\n",
       " {'loss': 1.6751,\n",
       "  'grad_norm': 0.2626553475856781,\n",
       "  'learning_rate': 2.8964862298195632e-05,\n",
       "  'epoch': 4.78,\n",
       "  'step': 560},\n",
       " {'loss': 1.6798,\n",
       "  'grad_norm': 0.29400232434272766,\n",
       "  'learning_rate': 2.8490028490028492e-05,\n",
       "  'epoch': 4.86,\n",
       "  'step': 570},\n",
       " {'loss': 1.6819,\n",
       "  'grad_norm': 0.22357694804668427,\n",
       "  'learning_rate': 2.8015194681861352e-05,\n",
       "  'epoch': 4.95,\n",
       "  'step': 580},\n",
       " {'eval_loss': 1.6822822093963623,\n",
       "  'eval_accuracy': 0.786,\n",
       "  'eval_runtime': 1.1421,\n",
       "  'eval_samples_per_second': 8755.433,\n",
       "  'eval_steps_per_second': 69.168,\n",
       "  'epoch': 5.0,\n",
       "  'step': 586},\n",
       " {'loss': 1.6825,\n",
       "  'grad_norm': 0.1871277540922165,\n",
       "  'learning_rate': 2.754036087369421e-05,\n",
       "  'epoch': 5.03,\n",
       "  'step': 590},\n",
       " {'loss': 1.6719,\n",
       "  'grad_norm': 0.2967647314071655,\n",
       "  'learning_rate': 2.706552706552707e-05,\n",
       "  'epoch': 5.12,\n",
       "  'step': 600},\n",
       " {'loss': 1.6815,\n",
       "  'grad_norm': 0.25162702798843384,\n",
       "  'learning_rate': 2.6590693257359926e-05,\n",
       "  'epoch': 5.2,\n",
       "  'step': 610},\n",
       " {'loss': 1.6816,\n",
       "  'grad_norm': 0.31333717703819275,\n",
       "  'learning_rate': 2.611585944919278e-05,\n",
       "  'epoch': 5.29,\n",
       "  'step': 620},\n",
       " {'loss': 1.671,\n",
       "  'grad_norm': 0.25033578276634216,\n",
       "  'learning_rate': 2.564102564102564e-05,\n",
       "  'epoch': 5.37,\n",
       "  'step': 630},\n",
       " {'loss': 1.6739,\n",
       "  'grad_norm': 0.30464187264442444,\n",
       "  'learning_rate': 2.51661918328585e-05,\n",
       "  'epoch': 5.46,\n",
       "  'step': 640},\n",
       " {'loss': 1.6852,\n",
       "  'grad_norm': 0.2800043523311615,\n",
       "  'learning_rate': 2.4691358024691357e-05,\n",
       "  'epoch': 5.54,\n",
       "  'step': 650},\n",
       " {'loss': 1.6779,\n",
       "  'grad_norm': 0.24466894567012787,\n",
       "  'learning_rate': 2.4216524216524217e-05,\n",
       "  'epoch': 5.63,\n",
       "  'step': 660},\n",
       " {'loss': 1.6692,\n",
       "  'grad_norm': 0.1920284777879715,\n",
       "  'learning_rate': 2.3741690408357077e-05,\n",
       "  'epoch': 5.71,\n",
       "  'step': 670},\n",
       " {'loss': 1.674,\n",
       "  'grad_norm': 0.6195860505104065,\n",
       "  'learning_rate': 2.3266856600189934e-05,\n",
       "  'epoch': 5.8,\n",
       "  'step': 680},\n",
       " {'loss': 1.672,\n",
       "  'grad_norm': 0.30792859196662903,\n",
       "  'learning_rate': 2.2792022792022794e-05,\n",
       "  'epoch': 5.88,\n",
       "  'step': 690},\n",
       " {'loss': 1.6718,\n",
       "  'grad_norm': 0.2580995559692383,\n",
       "  'learning_rate': 2.2317188983855654e-05,\n",
       "  'epoch': 5.97,\n",
       "  'step': 700},\n",
       " {'eval_loss': 1.676903486251831,\n",
       "  'eval_accuracy': 0.7911,\n",
       "  'eval_runtime': 1.115,\n",
       "  'eval_samples_per_second': 8968.683,\n",
       "  'eval_steps_per_second': 70.853,\n",
       "  'epoch': 6.0,\n",
       "  'step': 703},\n",
       " {'loss': 1.6714,\n",
       "  'grad_norm': 0.18019509315490723,\n",
       "  'learning_rate': 2.184235517568851e-05,\n",
       "  'epoch': 6.06,\n",
       "  'step': 710},\n",
       " {'loss': 1.6822,\n",
       "  'grad_norm': 0.298174649477005,\n",
       "  'learning_rate': 2.1367521367521368e-05,\n",
       "  'epoch': 6.14,\n",
       "  'step': 720},\n",
       " {'loss': 1.6735,\n",
       "  'grad_norm': 0.2913382351398468,\n",
       "  'learning_rate': 2.0892687559354228e-05,\n",
       "  'epoch': 6.23,\n",
       "  'step': 730},\n",
       " {'loss': 1.6604,\n",
       "  'grad_norm': 0.1930808126926422,\n",
       "  'learning_rate': 2.0417853751187084e-05,\n",
       "  'epoch': 6.31,\n",
       "  'step': 740},\n",
       " {'loss': 1.666,\n",
       "  'grad_norm': 0.24745598435401917,\n",
       "  'learning_rate': 1.9943019943019945e-05,\n",
       "  'epoch': 6.4,\n",
       "  'step': 750},\n",
       " {'loss': 1.6736,\n",
       "  'grad_norm': 0.2863791882991791,\n",
       "  'learning_rate': 1.9468186134852805e-05,\n",
       "  'epoch': 6.48,\n",
       "  'step': 760},\n",
       " {'loss': 1.6789,\n",
       "  'grad_norm': 0.2587968707084656,\n",
       "  'learning_rate': 1.899335232668566e-05,\n",
       "  'epoch': 6.57,\n",
       "  'step': 770},\n",
       " {'loss': 1.6688,\n",
       "  'grad_norm': 0.2973743677139282,\n",
       "  'learning_rate': 1.8518518518518518e-05,\n",
       "  'epoch': 6.65,\n",
       "  'step': 780},\n",
       " {'loss': 1.6732,\n",
       "  'grad_norm': 0.3742157816886902,\n",
       "  'learning_rate': 1.804368471035138e-05,\n",
       "  'epoch': 6.74,\n",
       "  'step': 790},\n",
       " {'loss': 1.6643,\n",
       "  'grad_norm': 0.3636986315250397,\n",
       "  'learning_rate': 1.7568850902184235e-05,\n",
       "  'epoch': 6.82,\n",
       "  'step': 800},\n",
       " {'loss': 1.6694,\n",
       "  'grad_norm': 0.46354132890701294,\n",
       "  'learning_rate': 1.7094017094017095e-05,\n",
       "  'epoch': 6.91,\n",
       "  'step': 810},\n",
       " {'loss': 1.6765,\n",
       "  'grad_norm': 0.2402416616678238,\n",
       "  'learning_rate': 1.6619183285849956e-05,\n",
       "  'epoch': 6.99,\n",
       "  'step': 820},\n",
       " {'eval_loss': 1.6744577884674072,\n",
       "  'eval_accuracy': 0.7925,\n",
       "  'eval_runtime': 1.2496,\n",
       "  'eval_samples_per_second': 8002.541,\n",
       "  'eval_steps_per_second': 63.22,\n",
       "  'epoch': 6.99,\n",
       "  'step': 820},\n",
       " {'loss': 1.6731,\n",
       "  'grad_norm': 0.4012235105037689,\n",
       "  'learning_rate': 1.6144349477682812e-05,\n",
       "  'epoch': 7.08,\n",
       "  'step': 830},\n",
       " {'loss': 1.6728,\n",
       "  'grad_norm': 0.5217567086219788,\n",
       "  'learning_rate': 1.566951566951567e-05,\n",
       "  'epoch': 7.16,\n",
       "  'step': 840},\n",
       " {'loss': 1.6632,\n",
       "  'grad_norm': 0.20854675769805908,\n",
       "  'learning_rate': 1.5194681861348528e-05,\n",
       "  'epoch': 7.25,\n",
       "  'step': 850},\n",
       " {'loss': 1.6692,\n",
       "  'grad_norm': 0.2732464671134949,\n",
       "  'learning_rate': 1.4719848053181388e-05,\n",
       "  'epoch': 7.33,\n",
       "  'step': 860},\n",
       " {'loss': 1.6736,\n",
       "  'grad_norm': 0.16948573291301727,\n",
       "  'learning_rate': 1.4245014245014246e-05,\n",
       "  'epoch': 7.42,\n",
       "  'step': 870},\n",
       " {'loss': 1.6712,\n",
       "  'grad_norm': 0.48440298438072205,\n",
       "  'learning_rate': 1.3770180436847105e-05,\n",
       "  'epoch': 7.51,\n",
       "  'step': 880},\n",
       " {'loss': 1.661,\n",
       "  'grad_norm': 0.2539488673210144,\n",
       "  'learning_rate': 1.3295346628679963e-05,\n",
       "  'epoch': 7.59,\n",
       "  'step': 890},\n",
       " {'loss': 1.6656,\n",
       "  'grad_norm': 0.288784921169281,\n",
       "  'learning_rate': 1.282051282051282e-05,\n",
       "  'epoch': 7.68,\n",
       "  'step': 900},\n",
       " {'loss': 1.6641,\n",
       "  'grad_norm': 0.25025635957717896,\n",
       "  'learning_rate': 1.2345679012345678e-05,\n",
       "  'epoch': 7.76,\n",
       "  'step': 910},\n",
       " {'loss': 1.6677,\n",
       "  'grad_norm': 0.27192288637161255,\n",
       "  'learning_rate': 1.1870845204178538e-05,\n",
       "  'epoch': 7.85,\n",
       "  'step': 920},\n",
       " {'loss': 1.6698,\n",
       "  'grad_norm': 0.3746833801269531,\n",
       "  'learning_rate': 1.1396011396011397e-05,\n",
       "  'epoch': 7.93,\n",
       "  'step': 930},\n",
       " {'eval_loss': 1.6722298860549927,\n",
       "  'eval_accuracy': 0.7938,\n",
       "  'eval_runtime': 1.1799,\n",
       "  'eval_samples_per_second': 8475.203,\n",
       "  'eval_steps_per_second': 66.954,\n",
       "  'epoch': 8.0,\n",
       "  'step': 938},\n",
       " {'loss': 1.6729,\n",
       "  'grad_norm': 0.2602211833000183,\n",
       "  'learning_rate': 1.0921177587844255e-05,\n",
       "  'epoch': 8.02,\n",
       "  'step': 940},\n",
       " {'loss': 1.669,\n",
       "  'grad_norm': 0.20037823915481567,\n",
       "  'learning_rate': 1.0446343779677114e-05,\n",
       "  'epoch': 8.1,\n",
       "  'step': 950},\n",
       " {'loss': 1.6752,\n",
       "  'grad_norm': 0.26094651222229004,\n",
       "  'learning_rate': 9.971509971509972e-06,\n",
       "  'epoch': 8.19,\n",
       "  'step': 960},\n",
       " {'loss': 1.6739,\n",
       "  'grad_norm': 0.20958174765110016,\n",
       "  'learning_rate': 9.49667616334283e-06,\n",
       "  'epoch': 8.27,\n",
       "  'step': 970},\n",
       " {'loss': 1.6646,\n",
       "  'grad_norm': 0.33378204703330994,\n",
       "  'learning_rate': 9.02184235517569e-06,\n",
       "  'epoch': 8.36,\n",
       "  'step': 980},\n",
       " {'loss': 1.6603,\n",
       "  'grad_norm': 0.4429430365562439,\n",
       "  'learning_rate': 8.547008547008548e-06,\n",
       "  'epoch': 8.44,\n",
       "  'step': 990},\n",
       " {'loss': 1.6675,\n",
       "  'grad_norm': 0.2547042965888977,\n",
       "  'learning_rate': 8.072174738841406e-06,\n",
       "  'epoch': 8.53,\n",
       "  'step': 1000},\n",
       " {'loss': 1.6637,\n",
       "  'grad_norm': 0.2030046433210373,\n",
       "  'learning_rate': 7.597340930674264e-06,\n",
       "  'epoch': 8.61,\n",
       "  'step': 1010},\n",
       " {'loss': 1.6694,\n",
       "  'grad_norm': 0.48614832758903503,\n",
       "  'learning_rate': 7.122507122507123e-06,\n",
       "  'epoch': 8.7,\n",
       "  'step': 1020},\n",
       " {'loss': 1.657,\n",
       "  'grad_norm': 0.26008814573287964,\n",
       "  'learning_rate': 6.6476733143399815e-06,\n",
       "  'epoch': 8.78,\n",
       "  'step': 1030},\n",
       " {'loss': 1.671,\n",
       "  'grad_norm': 0.2580671012401581,\n",
       "  'learning_rate': 6.172839506172839e-06,\n",
       "  'epoch': 8.87,\n",
       "  'step': 1040},\n",
       " {'loss': 1.6645,\n",
       "  'grad_norm': 0.3807239830493927,\n",
       "  'learning_rate': 5.6980056980056985e-06,\n",
       "  'epoch': 8.96,\n",
       "  'step': 1050},\n",
       " {'eval_loss': 1.6709222793579102,\n",
       "  'eval_accuracy': 0.7952,\n",
       "  'eval_runtime': 1.18,\n",
       "  'eval_samples_per_second': 8474.697,\n",
       "  'eval_steps_per_second': 66.95,\n",
       "  'epoch': 9.0,\n",
       "  'step': 1055},\n",
       " {'loss': 1.6625,\n",
       "  'grad_norm': 0.4656953513622284,\n",
       "  'learning_rate': 5.223171889838557e-06,\n",
       "  'epoch': 9.04,\n",
       "  'step': 1060},\n",
       " {'loss': 1.67,\n",
       "  'grad_norm': 0.30674678087234497,\n",
       "  'learning_rate': 4.748338081671415e-06,\n",
       "  'epoch': 9.13,\n",
       "  'step': 1070},\n",
       " {'loss': 1.6653,\n",
       "  'grad_norm': 0.1640467643737793,\n",
       "  'learning_rate': 4.273504273504274e-06,\n",
       "  'epoch': 9.21,\n",
       "  'step': 1080},\n",
       " {'loss': 1.6613,\n",
       "  'grad_norm': 0.22133222222328186,\n",
       "  'learning_rate': 3.798670465337132e-06,\n",
       "  'epoch': 9.3,\n",
       "  'step': 1090},\n",
       " {'loss': 1.6759,\n",
       "  'grad_norm': 0.3350549340248108,\n",
       "  'learning_rate': 3.3238366571699908e-06,\n",
       "  'epoch': 9.38,\n",
       "  'step': 1100},\n",
       " {'loss': 1.6516,\n",
       "  'grad_norm': 0.30921298265457153,\n",
       "  'learning_rate': 2.8490028490028492e-06,\n",
       "  'epoch': 9.47,\n",
       "  'step': 1110},\n",
       " {'loss': 1.6615,\n",
       "  'grad_norm': 0.35642683506011963,\n",
       "  'learning_rate': 2.3741690408357077e-06,\n",
       "  'epoch': 9.55,\n",
       "  'step': 1120},\n",
       " {'loss': 1.6661,\n",
       "  'grad_norm': 0.3346767723560333,\n",
       "  'learning_rate': 1.899335232668566e-06,\n",
       "  'epoch': 9.64,\n",
       "  'step': 1130},\n",
       " {'loss': 1.6738,\n",
       "  'grad_norm': 0.28334125876426697,\n",
       "  'learning_rate': 1.4245014245014246e-06,\n",
       "  'epoch': 9.72,\n",
       "  'step': 1140},\n",
       " {'loss': 1.6703,\n",
       "  'grad_norm': 0.34023958444595337,\n",
       "  'learning_rate': 9.49667616334283e-07,\n",
       "  'epoch': 9.81,\n",
       "  'step': 1150},\n",
       " {'loss': 1.6661,\n",
       "  'grad_norm': 0.2682780921459198,\n",
       "  'learning_rate': 4.748338081671415e-07,\n",
       "  'epoch': 9.89,\n",
       "  'step': 1160},\n",
       " {'loss': 1.6694,\n",
       "  'grad_norm': 0.26922735571861267,\n",
       "  'learning_rate': 0.0,\n",
       "  'epoch': 9.98,\n",
       "  'step': 1170},\n",
       " {'eval_loss': 1.6704211235046387,\n",
       "  'eval_accuracy': 0.7956,\n",
       "  'eval_runtime': 1.173,\n",
       "  'eval_samples_per_second': 8524.996,\n",
       "  'eval_steps_per_second': 67.347,\n",
       "  'epoch': 9.98,\n",
       "  'step': 1170},\n",
       " {'train_runtime': 99.3643,\n",
       "  'train_samples_per_second': 6038.383,\n",
       "  'train_steps_per_second': 11.775,\n",
       "  'total_flos': 0.0,\n",
       "  'train_loss': 1.7484506672264164,\n",
       "  'epoch': 9.98,\n",
       "  'step': 1170}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
